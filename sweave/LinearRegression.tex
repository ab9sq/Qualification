\documentclass[10pt]{article}

\usepackage[toc]{multitoc}
\renewcommand*{\multicolumntoc}{2}
%\setlength{\columnseprule}{0.5pt}


\title{Qualification of R Linear Regression}
\author{Nick Lauerman}

\usepackage{Sweave}
\begin{document}
\input{LinearRegression-concordance}
\maketitle

\begin{abstract}
Evaulation of various NIST data sets for linear regression to see how to model
them in R and to use them for the perpose of qualifing R for general statistical
use.
\end{abstract}

\tableofcontents

\section{Setup}
\subsection{R}
This seriess of tests is being run on R with only the ``base'' packages or libraries
installed. The following commands are issued prior to runing hte tests for the 
reason stated

\begin{description}
   \item[options(digits = 15)] This is used to specify that 15 digits are to be displayed
   on numbers.
   \item[path] Sets the path to the directory were the data sets are stored.
\end{description}
\begin{Schunk}
\begin{Sinput}
> options(digits = 15)
> path="~/R/workspace/qual/raw data/Linear Regression/"
\end{Sinput}
\end{Schunk}
\subsection{Computer Information}
The degree of accuracy  that can be expected from a computer if a function of several
factors including the processor used. R provides a method to determine numeric tolerance based on 
David Goldberg (1991), ``What Every Computer Scientist Should Know About Floating-Point Arithmetic''
, ACM Computing Surveys, 23/1, 5 \- 48, also available via http://www.validlab.com/goldberg/paper.pdf.

This value can be treated as the error value for the computer and for accuracy beyond requires careful
consideration.

\begin{Schunk}
\begin{Sinput}
> .Machine$double.eps ^ 0.5
\end{Sinput}
\begin{Soutput}
[1] 1.49011611938477e-08
\end{Soutput}
\end{Schunk}
\subsection{R Information}
\begin{Schunk}
\begin{Sinput}
> version
\end{Sinput}
\begin{Soutput}
               _                           
platform       i386-w64-mingw32            
arch           i386                        
os             mingw32                     
system         i386, mingw32               
status                                     
major          3                           
minor          3.0                         
year           2016                        
month          05                          
day            03                          
svn rev        70573                       
language       R                           
version.string R version 3.3.0 (2016-05-03)
nickname       Supposedly Educational      
\end{Soutput}
\end{Schunk}
\subsection{Data Cleaning}
all data sets downloaded from NIST as a DAT (ASCII Format) file were cleaned up 
to remove header information that was imbeded in the file. The file was than saved
as a TXT file without any additional changes. This clean up was done to simplify 
the loading of the data into R.

\section{Background Information}

\begin{quote}
Even with the availability of reliable code for linear least squares fitting, problems persist. Failure to use the best algorithms and to implement them most effectively is often the cause. Therefore, we provide datasets with certified values for key statistics for testing linear least squares code. 
Both generated and "real-world" data are included. Generated datasets challenge specific computations and include the Wampler data developed at NIST (formerly NBS) in the early 1970's. Real-world data include the challenging Longley data, as well as more benign datasets from our statistical consulting work at NIST. 

Datasets are ordered by level of difficulty (lower, average, and higher). Strictly speaking the level of difficulty of a dataset depends on the algorithm used. These levels are intended to provide rough guidance for the user. Datasets of lower level of difficulty should pose few problems for most code. Discrepancies here may indicate a failure to use correct options for the code. Two datasets are included for fitting a line through the origin. We have encountered codes that produce negative R-squared and incorrect F-statistics for these datasets. Therefore, we assign them an "average" level of difficulty. Finally, several datasets of higher level of difficulty are provided. These datasets are multicollinear. They include the Longley data and several NIST datasets developed by Wampler. 

Producing correct results on all datasets of higher difficulty does not imply that your software will pass all datasets of average or even lower difficulty. Similarly, producing correct results for all datasets in this collection does not imply that your software will do the same for your particular dataset. It will, however, provide some degree of assurance, in the sense that your package provides correct results for datasets known to yield incorrect results for some software. 

Certified values are provided for the parameter estimates, their standard deviations, the residual standard deviation, R-squared, and the standard ANOVA table for linear regression. Certified values are quoted to 16 significant digits and are accurate up to the last digit, due to possible truncation errors. For more information on certification methodology, see the description provided for each dataset. 

If your code fails to produce correct results for a dataset of higher level of difficulty, one possible remedy is to center the data and rerun the code. Centering the data, i.e., subtracting the mean for each predictor variable, reduces the degree of multicollinearity. The code may produce correct results for the centered data. You can judge this by comparing predicted values from the fit of centered data with those from the certified fit. 

We plan to update this collection of datasets, and welcome your feedback on specific datasets to include, and on other ways to improve this web service.
\end{quote}

\section{Norris Data Set}
Using the Norris data set (http://www.itl.nist.gov/div898/strd/lls/data/Norris.shtml)
\subsection*{Data Set Description}

These data are from a NIST study involving calibration of ozone monitors. The 
response variable (y) is the customer's measurement of ozone concentration and 
the predictor variable (x) is NIST's measurement of ozone concentration.  

\subsection*{About the data set}

\begin{description}
   \item[]Data Set Properties
   \item[Level of Difficulty] Lower
   \item[Model Class] Linear
   \item[Number of Parameters] 2   
   \item[Number of observations] 36
   \item[Predictor variable(s)] 1
   \item[Response variable] 1
\end{description}

Certifed Regression Statistics

\begin{tabular}{lll}
   \textbf{Parameter} & \textbf{Estimate} & \textbf{Standard Deviation of Estimate}  \\ 
	\textbf{Intercept} & -0.262323073774029 &  0.232818234301152\\ 
	\textbf{X} & 1.00211681802045  &  0.429796848199937E-03 \\ 
	\ 
\end{tabular} 

\begin{tabular}{ll}
    \textbf{Residual Standard Deviation} &  0.884796396144373  \\ 
	 \textbf{R-Squared} & 0.999993745883712    \\  
\end{tabular}

Certified Analysis of Variance Table

\begin{tabular}{lllll}
   \textbf{Source of Variation} & \textbf{Degrees of Freedom} & \textbf{Sums of Squares} & \textbf{Mean Squares} & \textbf{F Statistic} \\ 
   \textbf{Regression} & 1 & 4255954.13232369 & 4255954.13232369 & 5436385.54079785  \\ 
	\textbf{Residual} & 34 & 26.6173985294224 & 0.782864662630069 &  \\ 
\end{tabular}

\begin{Schunk}
\begin{Sinput}
> Norris <- read.table(file=paste0(path,"Norris.txt"), header=TRUE)
> Norris.lm <- lm(y~x, data=Norris)
> summary(Norris.lm)
\end{Sinput}
\begin{Soutput}
Call:
lm(formula = y ~ x, data = Norris)

Residuals:
             Min               1Q           Median               3Q 
-2.3523781286599 -0.5326967162014 -0.0296292259639  0.6000277736811 
             Max 
 1.7897858528801 

Coefficients:
                    Estimate       Std. Error    t value Pr(>|t|)    
(Intercept) -0.2623230737739  0.2328182343012   -1.12673  0.26775    
x            1.0021168180205  0.0004297968482 2331.60579  < 2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.884796396144 on 34 degrees of freedom
Multiple R-squared:  0.999993745884,	Adjusted R-squared:  0.999993561939 
F-statistic:  5436385.5408 on 1 and 34 DF,  p-value: < 2.220446049e-16
\end{Soutput}
\begin{Sinput}
> anova(Norris.lm)
\end{Sinput}
\begin{Soutput}
Analysis of Variance Table

Response: y
          Df         Sum Sq        Mean Sq      F value     Pr(>F)    
x          1 4255954.132324 4255954.132324 5436385.5408 < 2.22e-16 ***
Residuals 34      26.617399       0.782865                            
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{Soutput}
\end{Schunk}


\section{Pontius}
Using the Pontius data set (http://www.itl.nist.gov/div898/strd/lls/data/Pontius.shtml)

\subsection*{Data Set Description}
These data are from a NIST study involving calibration of load cells. The response variable (y) is the deflection and the predictor variable (x) is load.


\subsection*{About the data set}

\begin{description}
   \item[]Data Set Properties
   \item[Level of Difficulty] Lower
   \item[Model Class] Quadratic
   \item[Number of Parameters] 3
   \item[Number of observations] 40
   \item[Predictor variable(s)] 1
   \item[Response variable] 1
\end{description}

\begin{tabular}{lll}
   \textbf{Parameter} & \textbf{Estimate} & \textbf{Standard Deviation of Estimate}  \\ 
   \textbf{Intercept} & 0.673565789473684E-03 &  0.107938612033077E-03\\ 
	\textbf{X} & 0.732059160401003E-06  &   0.157817399981659E-09 \\ 
   \textbf{X 2} & -0.316081871345029E-14  &  0.486652849992036E-16 \\ 
\end{tabular} 

\begin{tabular}{ll}
    \textbf{Residual Standard Deviation} &  0.205177424076185E-03  \\ 
    \textbf{R-Squared} & 0.99999990017853   \\  
\end{tabular}


\begin{tabular}{lllll}
   \textbf{Source of Variation} & \textbf{Degrees of Freedom} & \textbf{Sums of Squares} & \textbf{Mean Squares}  & \textbf{F Statistic} \\ 
   \textbf{Regression} & 2 & 15.6040343244198 & 7.80201716220991 & 185330865.995752 \\ 
	\textbf{Residual} & 37 & 0.155761768796992E-05 & 0.420977753505385E-07 &  \\ 
\end{tabular} 

\begin{Schunk}
\begin{Sinput}
> Pontius <- read.table(file=paste0(path,"Pontius.txt"), header=TRUE)
> Pontius.lm <- lm(y~x + I(x^2), data=Pontius)
> summary(Pontius.lm)
\end{Sinput}
\begin{Soutput}
Call:
lm(formula = y ~ x + I(x^2), data = Pontius)

Residuals:
               Min                 1Q             Median                 3Q 
-4.46840225565e-04 -1.57827067669e-04  3.81729323308e-05  1.08788533835e-04 
               Max 
 4.23453007519e-04 

Coefficients:
                      Estimate         Std. Error    t value   Pr(>|t|)    
(Intercept)  6.73565789473e-04  1.07938612033e-04    6.24027 2.9705e-07 ***
x            7.32059160401e-07  1.57817399982e-10 4638.64669 < 2.22e-16 ***
I(x^2)      -3.16081871345e-15  4.86652849992e-17  -64.95017 < 2.22e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.000205177424076 on 37 degrees of freedom
Multiple R-squared:  0.999999900179,	Adjusted R-squared:  0.999999894783 
F-statistic: 185330865.996 on 2 and 37 DF,  p-value: < 2.220446049e-16
\end{Soutput}
\begin{Sinput}
> anova(Pontius.lm)
\end{Sinput}
\begin{Soutput}
Analysis of Variance Table

Response: y
          Df          Sum Sq         Mean Sq         F value     Pr(>F)    
x          1 15.603856733899 15.603856733899 370657513.46626 < 2.22e-16 ***
I(x^2)     1  0.000177590520  0.000177590520      4218.52506 < 2.22e-16 ***
Residuals 37  0.000001557618  0.000000042098                               
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{Soutput}
\end{Schunk}

\section{NoInt1}
Using the NoInt1 data set (http://www.itl.nist.gov/div898/strd/lls/data/NoInt1.shtml)

\subsection*{Data Set Description}
This dataset is constructed to test the ability of the software to recognize a 
statistically significant slope for a line fit through the origin (large positive 
value of the F statistic)

\subsection*{About the data set}

\begin{description}
   \item[]Data Set Properties
   \item[Level of Difficulty] Average
   \item[Model Class] linear
   \item[Number of Parameters] 1
   \item[Number of observations] 11
   \item[Predictor variable(s)] 1
   \item[Response variable] 1
\end{description}

\begin{tabular}{lll}
   \textbf{Parameter} & \textbf{Estimate} & \textbf{Standard Deviation of Estimate}  \\ 
	 \textbf{X} &  2.07438016528926 &  0.165289256198347E-01  \\ 
\end{tabular} 

\begin{tabular}{ll}
    \textbf{Residual Standard Deviation} &  3.56753034006338  \\ 
    \textbf{R-Squared} & 0.999365492298663   \\  
\end{tabular}


\begin{tabular}{lllll}
   \textbf{Source of Variation} & \textbf{Degrees of Freedom} & \textbf{Sums of Squares} & \textbf{Mean Squares}  & \textbf{F Statistic} \\ 
   \textbf{Regression} & 1 & 200457.727272727 & 200457.727272727 & 15750.2500000000 \\ 
	\textbf{Residual} & 10 & 127.272727272727 & 12.7272727272727 &  \\ 
\end{tabular} 

\begin{Schunk}
\begin{Sinput}
> NoInt1 <- read.table(file=paste0(path,"NoInt1.txt"), header=TRUE)
> NoInt1.lm <- lm(y~x + 0, data=NoInt1)
> summary(NoInt1.lm)
\end{Sinput}
\begin{Soutput}
Call:
lm(formula = y ~ x + 0, data = NoInt1)

Residuals:
            Min              1Q          Median              3Q             Max 
-5.206611570248 -2.520661157025  0.165289256198  2.851239669421  5.537190082645 

Coefficients:
         Estimate      Std. Error t value   Pr(>|t|)    
x 2.0743801652893 0.0165289256198   125.5 < 2.22e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.56753034006 on 10 degrees of freedom
Multiple R-squared:  0.999365492299,	Adjusted R-squared:  0.999302041529 
F-statistic:      15750.25 on 1 and 10 DF,  p-value: < 2.220446049e-16
\end{Soutput}
\begin{Sinput}
> anova(NoInt1.lm)
\end{Sinput}
\begin{Soutput}
Analysis of Variance Table

Response: y
          Df          Sum Sq         Mean Sq  F value     Pr(>F)    
x          1 200457.72727273 200457.72727273 15750.25 < 2.22e-16 ***
Residuals 10    127.27272727     12.72727273                        
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{Soutput}
\end{Schunk}

\section{NoInt2}
Using the NoInt2 data set (http://www.itl.nist.gov/div898/strd/lls/data/NoInt2.shtml)

\subsection*{Data Set Description}



\subsection*{About the data set}

\begin{description}
   \item[]Data Set Properties
   \item[Level of Difficulty]Average
   \item[Model Class]Linear
   \item[Number of Parameters]1
   \item[Number of observations]3
   \item[Predictor variable(s)]1
   \item[Response variable]1
\end{description}

\begin{tabular}{lll}
   \textbf{Parameter} & \textbf{Estimate} & \textbf{Standard Deviation of Estimate}  \\ 
	\textbf{X} &   0.727272727272727 &   \\ 
	  &   &  \\ 
\end{tabular} 

\begin{tabular}{ll}
    \textbf{Residual Standard Deviation} & 0.369274472937998    \\ 
    \textbf{R-Squared} & 0.993348115299335   \\  
\end{tabular}


\begin{tabular}{lllll}
   \textbf{Source of Variation} & \textbf{Degrees of Freedom} & \textbf{Sums of Squares} & \textbf{Mean Squares}  & \textbf{F Statistic} \\ 
   \textbf{Regression} & 1 & 40.7272727272727 & 0.7272727272727 & 298.66666666666 \\ 
	\textbf{Residual} & 2 & 0.272727272727273 & 0.136363636363636  \\ 
\end{tabular} 

\begin{Schunk}
\begin{Sinput}
> NoInt2 <- read.table(file=paste0(path,"NoInt2.txt"), header=TRUE)
> NoInt2.lm <- lm(y~x + 0, data=NoInt2)
> summary(NoInt2.lm)
\end{Sinput}
\begin{Soutput}
Call:
lm(formula = y ~ x + 0, data = NoInt2)

Residuals:
               1                2                3 
 0.0909090909091  0.3636363636364 -0.3636363636364 

Coefficients:
         Estimate      Std. Error  t value  Pr(>|t|)   
x 0.7272727272727 0.0420827318078 17.28198 0.0033315 **
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.369274472938 on 2 degrees of freedom
Multiple R-squared:  0.993348115299,	Adjusted R-squared:  0.990022172949 
F-statistic: 298.666666667 on 1 and 2 DF,  p-value: 0.00333149176904
\end{Soutput}
\begin{Sinput}
> anova(NoInt2.lm)
\end{Sinput}
\begin{Soutput}
Analysis of Variance Table

Response: y
          Df         Sum Sq        Mean Sq   F value    Pr(>F)   
x          1 40.72727272727 40.72727272727 298.66667 0.0033315 **
Residuals  2  0.27272727273  0.13636363636                       
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{Soutput}
\end{Schunk}


\section{Filip}
Using the Filip data set (http://www.itl.nist.gov/div898/strd/lls/data/Filip.shtml)

\subsection*{Data Set Description}
None supplied


\subsection*{About the data set}

\begin{description}
   \item[]Data Set Properties
   \item[Level of Difficulty] Higher
   \item[Model Class] Polynomial
   \item[Number of Parameters] 11
   \item[Number of observations]82
   \item[Predictor variable(s)]1
   \item[Response variable]1
\end{description}

\begin{tabular}{lll}
   \textbf{Parameter} & \textbf{Estimate} & \textbf{Standard Deviation of Estimate}  \\ 
   \textbf{Intercept} &-1467.48961422980    &    298.084530995537 \\ 
	\textbf{X} &  -2772.17959193342     &   559.779865474950  \\ 
   \textbf{X 2} &   -2316.37108160893   &     466.477572127796  \\ 
   \textbf{X 3} &   -1127.97394098372   &     227.204274477751  \\ 
   \textbf{X 4} &   -354.478233703349    &    71.6478660875927  \\ 
   \textbf{X 5} &   -75.1242017393757    &    15.2897178747400  \\ 
   \textbf{X 6} &  -10.8753180355343    &    2.23691159816033 \\ 
   \textbf{X 7} &    -1.06221498588947   &     0.221624321934227   \\ 
   \textbf{X 8} &   -0.670191154593408E-01  &      0.142363763154724E-01   \\ 
   \textbf{X 9} &   -0.246781078275479E-02   &     0.535617408889821E-03   \\ 
   \textbf{X 10} &   -0.402962525080404E-04    &    0.896632837373868E-05  \\ 
\end{tabular} 

\begin{tabular}{ll}
    \textbf{Residual Standard Deviation} &  0.334801051324544E-02  \\ 
    \textbf{R-Squared} &  0.996727416185620   \\  
\end{tabular}


\begin{tabular}{lllll}
   \textbf{Source of Variation} & \textbf{Degrees of Freedom} & \textbf{Sums of Squares} & \textbf{Mean Squares}  & \textbf{F Statistic} \\ 
   \textbf{Regression} & 10 & 0.242391619837339 &  0.242391619837339E-01	& 2162.43954511489   \\ 
	\textbf{Residual} &  71  & 0.795851382172941E-03 &	0.112091743968020E-04  \\ 
\end{tabular} 

\begin{Schunk}
\begin{Sinput}
> Filip <- read.table(file=paste0(path,"Filip.txt"), header=TRUE)
> Filip.lm <- lm(y ~ poly(x,10,raw = TRUE), data=Filip)
> summary(Filip.lm)
\end{Sinput}
\begin{Soutput}
Call:
lm(formula = y ~ poly(x, 10, raw = TRUE), data = Filip)

Residuals:
               Min                 1Q             Median                 3Q 
-0.009908657609788 -0.002461025802951  0.000338470305767  0.002074343930029 
               Max 
 0.007165411222262 

Coefficients: (1 not defined because of singularities)
                                    Estimate         Std. Error  t value
(Intercept)               -1.74280441508e+02  8.75611625044e+01 -1.99039
poly(x, 10, raw = TRUE)1  -3.26882203054e+02  1.48049618677e+02 -2.20792
poly(x, 10, raw = TRUE)2  -2.66056535478e+02  1.09512084924e+02 -2.42947
poly(x, 10, raw = TRUE)3  -1.23921612332e+02  4.65247149081e+01 -2.66357
poly(x, 10, raw = TRUE)4  -3.63816703934e+01  1.25145201072e+01 -2.90716
poly(x, 10, raw = TRUE)5  -6.97918828359e+00  2.21116610878e+00 -3.15634
poly(x, 10, raw = TRUE)6  -8.74660167593e-01  2.56744909446e-01 -3.40673
poly(x, 10, raw = TRUE)7  -6.90600966032e-02  1.89005629376e-02 -3.65386
poly(x, 10, raw = TRUE)8  -3.11832186810e-03  8.00878988763e-04 -3.89362
poly(x, 10, raw = TRUE)9  -6.13867077229e-05  1.48905169478e-05 -4.12254
poly(x, 10, raw = TRUE)10                 NA                 NA       NA
                            Pr(>|t|)    
(Intercept)               0.05034548 .  
poly(x, 10, raw = TRUE)1  0.03043560 *  
poly(x, 10, raw = TRUE)2  0.01761673 *  
poly(x, 10, raw = TRUE)3  0.00953389 ** 
poly(x, 10, raw = TRUE)4  0.00484493 ** 
poly(x, 10, raw = TRUE)5  0.00233320 ** 
poly(x, 10, raw = TRUE)6  0.00107912 ** 
poly(x, 10, raw = TRUE)7  0.00048725 ***
poly(x, 10, raw = TRUE)8  0.00021857 ***
poly(x, 10, raw = TRUE)9   9.907e-05 ***
poly(x, 10, raw = TRUE)10         NA    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.00376801219667 on 72 degrees of freedom
Multiple R-squared:  0.995796453079,	Adjusted R-squared:  0.995271009714 
F-statistic:  1895.1546812 on 9 and 72 DF,  p-value: < 2.220446049e-16
\end{Soutput}
\begin{Sinput}
> anova(Filip.lm)
\end{Sinput}
\begin{Soutput}
Analysis of Variance Table

Response: y
                        Df           Sum Sq           Mean Sq    F value
poly(x, 10, raw = TRUE)  9 0.24216522127368 0.026907246808187 1895.15468
Residuals               72 0.00102224994583 0.000014197915914           
                            Pr(>F)    
poly(x, 10, raw = TRUE) < 2.22e-16 ***
Residuals                             
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{Soutput}
\end{Schunk}

\begin{Schunk}
\begin{Sinput}
> Filip2.lm <- lm(y~x + 
+                    I(x^2) +
+                    I(x^3) +
+                    I(x^4) +
+                    I(x^5) +
+                    I(x^6) +
+                    I(x^7) +
+                    I(x^8) +
+                    I(x^9) +
+                    I(x^10) 
+                 , data=Filip)
> summary(Filip2.lm)
\end{Sinput}
\begin{Soutput}
Call:
lm(formula = y ~ x + I(x^2) + I(x^3) + I(x^4) + I(x^5) + I(x^6) + 
    I(x^7) + I(x^8) + I(x^9) + I(x^10), data = Filip)

Residuals:
               Min                 1Q             Median                 3Q 
-0.009908657609788 -0.002461025802951  0.000338470305767  0.002074343930029 
               Max 
 0.007165411222262 

Coefficients: (1 not defined because of singularities)
                      Estimate         Std. Error  t value   Pr(>|t|)    
(Intercept) -1.74280441508e+02  8.75611625044e+01 -1.99039 0.05034548 .  
x           -3.26882203054e+02  1.48049618677e+02 -2.20792 0.03043560 *  
I(x^2)      -2.66056535478e+02  1.09512084924e+02 -2.42947 0.01761673 *  
I(x^3)      -1.23921612332e+02  4.65247149081e+01 -2.66357 0.00953389 ** 
I(x^4)      -3.63816703934e+01  1.25145201072e+01 -2.90716 0.00484493 ** 
I(x^5)      -6.97918828359e+00  2.21116610878e+00 -3.15634 0.00233320 ** 
I(x^6)      -8.74660167593e-01  2.56744909446e-01 -3.40673 0.00107912 ** 
I(x^7)      -6.90600966032e-02  1.89005629376e-02 -3.65386 0.00048725 ***
I(x^8)      -3.11832186810e-03  8.00878988763e-04 -3.89362 0.00021857 ***
I(x^9)      -6.13867077229e-05  1.48905169478e-05 -4.12254  9.907e-05 ***
I(x^10)                     NA                 NA       NA         NA    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.00376801219667 on 72 degrees of freedom
Multiple R-squared:  0.995796453079,	Adjusted R-squared:  0.995271009714 
F-statistic:  1895.1546812 on 9 and 72 DF,  p-value: < 2.220446049e-16
\end{Soutput}
\begin{Sinput}
> anova(Filip2.lm)
\end{Sinput}
\begin{Soutput}
Analysis of Variance Table

Response: y
          Df           Sum Sq          Mean Sq     F value     Pr(>F)    
x          1 0.21288106025948 0.21288106025948 14993.82455 < 2.22e-16 ***
I(x^2)     1 0.00753409869624 0.00753409869624   530.64821 < 2.22e-16 ***
I(x^3)     1 0.00683749292831 0.00683749292831   481.58427 < 2.22e-16 ***
I(x^4)     1 0.00935927452572 0.00935927452572   659.20059 < 2.22e-16 ***
I(x^5)     1 0.00030458358215 0.00030458358215    21.45270 1.5707e-05 ***
I(x^6)     1 0.00380533483828 0.00380533483828   268.02066 < 2.22e-16 ***
I(x^7)     1 0.00004444148257 0.00004444148257     3.13014   0.081092 .  
I(x^8)     1 0.00115763695476 0.00115763695476    81.53570 1.8390e-13 ***
I(x^9)     1 0.00024129800617 0.00024129800617    16.99531 9.9070e-05 ***
Residuals 72 0.00102224994583 0.00001419791591                           
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{Soutput}
\end{Schunk}



\section{Longley}
Using the Longley data set (http://www.itl.nist.gov/div898/strd/lls/data/Longley.shtml)

\subsection*{Data Set Description}
This classic dataset of labor statistics was one of the first used to test the 
accuracy of least squares computations. The response variable (y) is the 
Total Derived Employment and the predictor variables are GNP Implicit Price Deflator 
with Year 1954 = 100 (x1), Gross National Product (x2), Unemployment (x3), 
Size of Armed Forces (x4), Non-Institutional Population Age 14 \& Over (x5), 
and Year (x6).


\subsection*{About the data set}

\begin{description}
   \item[]Data Set Properties
   \item[Level of Difficulty] Higher
   \item[Model Class] Multilinear
   \item[Number of Parameters] 7
   \item[Number of observations] 16
   \item[Predictor variable(s)] 6
   \item[Response variable] 1
\end{description}

\begin{tabular}{lll}
   \textbf{Parameter} & \textbf{Estimate} & \textbf{Standard Deviation of Estimate}  \\ 
   \textbf{Intercept} &  -3482258.63459582    &    890420.383607373 \\ 
	\textbf{X1} &   15.0618722713733    &    84.9149257747669   \\
   \textbf{X2} &   -0.358191792925910E-01  &      0.334910077722432E-01   \\
   \textbf{X3} &   -2.02022980381683     &   0.488399681651699  \\
   \textbf{X4} &   -1.03322686717359    &    0.214274163161675   \\
   \textbf{X5} &   -0.511041056535807E-01   &     0.226073200069370   \\
   \textbf{X6} &   1829.15146461355    &    455.478499142212   \\
\end{tabular} 

\begin{tabular}{ll}
    \textbf{Residual Standard Deviation} &   304.854073561965 \\ 
    \textbf{R-Squared} &  0.995479004577296  \\  
\end{tabular}


\begin{tabular}{lllll}
   \textbf{Source of Variation} & \textbf{Degrees of Freedom} & \textbf{Sums of Squares} & \textbf{Mean Squares}  & \textbf{F Statistic} \\ 
  \textbf{Regression} &  6  & 184172401.944494 &	30695400.3240823	& 330.285339234588  \\ 
	\textbf{Residual} &  9  & 836424.055505915 &	92936.0061673238 \\ 
\end{tabular} 

\begin{Schunk}
\begin{Sinput}
> Longley <- read.table(file=paste0(path,"Longley.txt"), header=TRUE)
> Longley.lm <- lm(y ~ .,data=Longley)
> summary(Longley.lm)
\end{Sinput}
\begin{Soutput}
Call:
lm(formula = y ~ ., data = Longley)

Residuals:
            Min              1Q          Median              3Q             Max 
-410.1146219309 -157.6747192954  -28.1619848188  101.5503832581  455.3940945519 

Coefficients:
                      Estimate         Std. Error  t value   Pr(>|t|)    
(Intercept) -3.48225863460e+06  8.90420383607e+05 -3.91080 0.00356040 ** 
x1           1.50618722714e+01  8.49149257748e+01  0.17738 0.86314083    
x2          -3.58191792926e-02  3.34910077722e-02 -1.06952 0.31268106    
x3          -2.02022980382e+00  4.88399681652e-01 -4.13643 0.00253509 ** 
x4          -1.03322686717e+00  2.14274163162e-01 -4.82199 0.00094437 ***
x5          -5.11041056536e-02  2.26073200069e-01 -0.22605 0.82621180    
x6           1.82915146461e+03  4.55478499142e+02  4.01589 0.00303680 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 304.854073562 on 9 degrees of freedom
Multiple R-squared:  0.995479004577,	Adjusted R-squared:  0.992465007629 
F-statistic: 330.285339235 on 6 and 9 DF,  p-value: 4.98403052872e-10
\end{Soutput}
\begin{Sinput}
> anova(Longley.lm)
\end{Sinput}
\begin{Soutput}
Analysis of Variance Table

Response: y
          Df          Sum Sq         Mean Sq    F value     Pr(>F)    
x1         1 174397449.77913 174397449.77913 1876.53265 9.2954e-12 ***
x2         1   4787181.04445   4787181.04445   51.51051 5.2109e-05 ***
x3         1   2263971.10982   2263971.10982   24.36054 0.00080706 ***
x4         1    876397.16186    876397.16186    9.43011 0.01333568 *  
x5         1    348589.39965    348589.39965    3.75085 0.08475523 .  
x6         1   1498813.44959   1498813.44959   16.12737 0.00303680 ** 
Residuals  9    836424.05551     92936.00617                          
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{Soutput}
\end{Schunk}








\end{document}

\section{}
Using the NoInt2 data set (http://www.itl.nist.gov/div898/strd/lls/data/Norris.shtml)

\subsection*{Data Set Description}



\subsection*{About the data set}

\begin{description}
   \item[]Data Set Properties
   \item[Level of Difficulty]
   \item[Model Class]
   \item[Number of Parameters]
   \item[Number of observations]
   \item[Predictor variable(s)]
   \item[Response variable]
\end{description}

\begin{tabular}{lll}
   \textbf{Parameter} & \textbf{Estimate} & \textbf{Standard Deviation of Estimate}  \\ 
	\textbf{Intercept} &  &  \\ 
	\textbf{X} &   &   \\ 
\end{tabular} 

\begin{tabular}{ll}
    \textbf{Residual Standard Deviation} &    \\ 
    \textbf{R-Squared} &    \\  
\end{tabular}


\begin{tabular}{lllll}
   \textbf{Source of Variation} & \textbf{Degrees of Freedom} & \textbf{Sums of Squares} & \textbf{Mean Squares}  & \textbf{F Statistic} \\ 
   \textbf{Regression} &  &  &  &  \\ 
	\textbf{Residual} &  &  &  &  \\ 
\end{tabular} 
